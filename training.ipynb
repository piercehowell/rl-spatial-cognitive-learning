{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_gridverse\n",
    "import torch\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "#Setup environment\n",
    "\n",
    "class FlattenObservationWrapper(gym.ObservationWrapper):\n",
    "\tdef __init__(self, env):\n",
    "\t\tsuper().__init__(env)\n",
    "\t\ttotal_size = sum(np.prod(env.observation_space.spaces[key].shape) for key in env.observation_space.spaces)\n",
    "\t\tself.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(total_size,), dtype=np.float32)\n",
    "\n",
    "\tdef observation(self, observation):\n",
    "\t\t# Flatten each part of the observation and then concatenate\n",
    "\t\tflattened_obs = np.concatenate([observation[key].flatten() for key in observation])\n",
    "\t\treturn flattened_obs\n",
    "\t\t\n",
    "def make_env():\n",
    "\tenv= gym.make(\"GV-FourRooms-9x9-v0\")\n",
    "\tenv = FlattenObservationWrapper(env)\n",
    "\treturn env\n",
    "\n",
    "\t\n",
    "\n",
    "\n",
    "#num_envs = 4 \n",
    "#env = SubprocVecEnv([make_env for _ in range(num_envs)],start_method='spawn')\n",
    "#num_envs = 8  # Number of parallel environments\n",
    "#env = DummyVecEnv([make_env for i in range(num_envs)])\n",
    "\n",
    "env = make_env()\n",
    "#env = FlattenObservationWrapper(env)\n",
    "#model = PPO(\"MultiInputPolicy\", env,verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./ppo_tensorboard/RecurrentPPO_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 453      |\n",
      "|    ep_rew_mean     | -16.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 288      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 299          |\n",
      "|    ep_rew_mean          | -8.89        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 179          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074336547 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.79        |\n",
      "|    explained_variance   | 0.00259      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0475       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    value_loss           | 0.794        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 311          |\n",
      "|    ep_rew_mean          | -9.53        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 160          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072141183 |\n",
      "|    clip_fraction        | 0.051        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.78        |\n",
      "|    explained_variance   | -0.000703    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0187       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    value_loss           | 1.58         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 320         |\n",
      "|    ep_rew_mean          | -10         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010027759 |\n",
      "|    clip_fraction        | 0.052       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | 0.00214     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.038       |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00136    |\n",
      "|    value_loss           | 1.4         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 385         |\n",
      "|    ep_rew_mean          | -13.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011893265 |\n",
      "|    clip_fraction        | 0.0895      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | 0.000878    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.76        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    value_loss           | 0.798       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 402        |\n",
      "|    ep_rew_mean          | -14.1      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 156        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 78         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00857745 |\n",
      "|    clip_fraction        | 0.0976     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.75      |\n",
      "|    explained_variance   | -0.00152   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0405     |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.00524   |\n",
      "|    value_loss           | 0.868      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 402         |\n",
      "|    ep_rew_mean          | -14.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011507124 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | 0.00738     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00626     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00994    |\n",
      "|    value_loss           | 1.03        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 426         |\n",
      "|    ep_rew_mean          | -15.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006125238 |\n",
      "|    clip_fraction        | 0.0559      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | -0.00194    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.38        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00522    |\n",
      "|    value_loss           | 1.86        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 428         |\n",
      "|    ep_rew_mean          | -15.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009635544 |\n",
      "|    clip_fraction        | 0.0776      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | -0.00366    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0143      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00458    |\n",
      "|    value_loss           | 1.05        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 377         |\n",
      "|    ep_rew_mean          | -12.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012340929 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | -0.00432    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.021       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    value_loss           | 1.51        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 386          |\n",
      "|    ep_rew_mean          | -13.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 144          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 155          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052463613 |\n",
      "|    clip_fraction        | 0.0372       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.71        |\n",
      "|    explained_variance   | -0.00161     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.88         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00587     |\n",
      "|    value_loss           | 3.56         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 388        |\n",
      "|    ep_rew_mean          | -13.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 146        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 167        |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01366272 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.71      |\n",
      "|    explained_variance   | 0.0027     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0212    |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    value_loss           | 1.33       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 383         |\n",
      "|    ep_rew_mean          | -13.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 147         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013688073 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | -0.000641   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0238     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 1.43        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 366         |\n",
      "|    ep_rew_mean          | -12.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 146         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 196         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015192998 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.00583     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0173      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 2.26        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 348         |\n",
      "|    ep_rew_mean          | -11.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 143         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 213         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012902743 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.000333    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0607      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    value_loss           | 2.82        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 336         |\n",
      "|    ep_rew_mean          | -10.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013132172 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.000451    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.45        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 3.24        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 331         |\n",
      "|    ep_rew_mean          | -10.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 249         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022901587 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.00701     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0513      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00882    |\n",
      "|    value_loss           | 2.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 335         |\n",
      "|    ep_rew_mean          | -10.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 138         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 266         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014521558 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | 0.0018      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0279      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00877    |\n",
      "|    value_loss           | 2.29        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 328         |\n",
      "|    ep_rew_mean          | -10.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 137         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 283         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015091135 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.00596     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0406      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 1.74        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 329         |\n",
      "|    ep_rew_mean          | -10.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 300         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016145691 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.0066      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.013      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 301        |\n",
      "|    ep_rew_mean          | -9.06      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 137        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 313        |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01630409 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.67      |\n",
      "|    explained_variance   | -0.00392   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0196    |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0186    |\n",
      "|    value_loss           | 1.1        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 305         |\n",
      "|    ep_rew_mean          | -9.24       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 330         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014341038 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.0015      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.17        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 3.09        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 282         |\n",
      "|    ep_rew_mean          | -8.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 345         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018884396 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | -0.00782    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0181     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    value_loss           | 1.1         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 287         |\n",
      "|    ep_rew_mean          | -8.37       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 361         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025824085 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.00359     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0189      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/kurt/Documents/HML/training.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kurt/Documents/HML/training.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     model\u001b[39m.\u001b[39mlearn(total_timesteps\u001b[39m=\u001b[39mtotal_timesteps, callback\u001b[39m=\u001b[39m[checkpoint_callback])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kurt/Documents/HML/training.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kurt/Documents/HML/training.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m model \u001b[39m=\u001b[39m train_model(env, total_timesteps\u001b[39m=\u001b[39;49m\u001b[39m1600000\u001b[39;49m)\n",
      "\u001b[1;32m/home/kurt/Documents/HML/training.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kurt/Documents/HML/training.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m checkpoint_callback \u001b[39m=\u001b[39m CheckpointCallback(save_freq\u001b[39m=\u001b[39m\u001b[39m10000\u001b[39m, save_path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./models/\u001b[39m\u001b[39m'\u001b[39m, name_prefix\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mppo_model_9x9\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kurt/Documents/HML/training.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Evaluation and logging\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kurt/Documents/HML/training.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m#eval_callback = EvalCallback(env, best_model_save_path='./models/', log_path='./logs/', eval_freq=50000)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kurt/Documents/HML/training.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps, callback\u001b[39m=\u001b[39;49m[checkpoint_callback])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kurt/Documents/HML/training.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/hml_gridverse/lib/python3.11/site-packages/sb3_contrib/ppo_recurrent/ppo_recurrent.py:490\u001b[0m, in \u001b[0;36mRecurrentPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mrecord(\u001b[39m\"\u001b[39m\u001b[39mtime/total_timesteps\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps, exclude\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtensorboard\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    488\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mdump(step\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps)\n\u001b[0;32m--> 490\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m    492\u001b[0m callback\u001b[39m.\u001b[39mon_training_end()\n\u001b[1;32m    494\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/hml_gridverse/lib/python3.11/site-packages/sb3_contrib/ppo_recurrent/ppo_recurrent.py:420\u001b[0m, in \u001b[0;36mRecurrentPPO.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[39m# Optimization step\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> 420\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    421\u001b[0m \u001b[39m# Clip grad norm\u001b[39;00m\n\u001b[1;32m    422\u001b[0m th\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy\u001b[39m.\u001b[39mparameters(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_grad_norm)\n",
      "File \u001b[0;32m~/miniconda3/envs/hml_gridverse/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/hml_gridverse/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training function\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback\n",
    "#model.learn(total_timesteps=1800000)\n",
    "\n",
    "def train_model(env, total_timesteps):\n",
    "    model = RecurrentPPO(\"MlpLstmPolicy\", env, verbose=2, device='cuda',n_steps=2048,tensorboard_log=\"./ppo_tensorboard/\")\n",
    "\n",
    "    # Save the model every 100k steps\n",
    "    checkpoint_callback = CheckpointCallback(save_freq=10000, save_path='./models/', name_prefix='ppo_model_9x9')\n",
    "\n",
    "    # Evaluation and logging\n",
    "    #eval_callback = EvalCallback(env, best_model_save_path='./models/', log_path='./logs/', eval_freq=50000)\n",
    "\n",
    "    model.learn(total_timesteps=total_timesteps, callback=[checkpoint_callback])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = train_model(env, total_timesteps=1600000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 5.3600001353770494, Std reward: 0.3907044812480032\n"
     ]
    }
   ],
   "source": [
    "#Test and save full trained model\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=20)\n",
    "print(f\"Mean reward: {mean_reward}, Std reward: {std_reward}\")\n",
    "model.save(\"ppo_gridworld_9x9_raytracing_1_8M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/kurt/Documents/HML/training.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kurt/Documents/HML/training.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m obs, rewards, dones, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kurt/Documents/HML/training.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m episode_starts \u001b[39m=\u001b[39m dones\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kurt/Documents/HML/training.ipynb#W3sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m env\u001b[39m.\u001b[39;49mrender()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kurt/Documents/HML/training.ipynb#W3sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mif\u001b[39;00m dones:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kurt/Documents/HML/training.ipynb#W3sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     obs \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/miniconda3/envs/hml_gridverse/lib/python3.11/site-packages/gym/core.py:295\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/hml_gridverse/lib/python3.11/site-packages/gym/core.py:295\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/hml_gridverse/lib/python3.11/site-packages/gym_gridverse/gym.py:166\u001b[0m, in \u001b[0;36mGymEnvironment.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[39m# without sleep the first frame could be black\u001b[39;00m\n\u001b[1;32m    164\u001b[0m         time\u001b[39m.\u001b[39msleep(\u001b[39m0.05\u001b[39m)\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_state_viewer\u001b[39m.\u001b[39;49mrender(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mouter_env\u001b[39m.\u001b[39;49minner_env\u001b[39m.\u001b[39;49mstate)\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhuman_observation\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_observation_viewer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/hml_gridverse/lib/python3.11/site-packages/gym_gridverse/rendering.py:632\u001b[0m, in \u001b[0;36mGridVerseViewer.render\u001b[0;34m(self, state_or_observation, action, reward, ret, done, return_rgb_array)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_viewer\u001b[39m.\u001b[39madd_onetime(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grid)\n\u001b[1;32m    631\u001b[0m other_drawables \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hud_layout] \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_draw_hud \u001b[39melse\u001b[39;00m []\n\u001b[0;32m--> 632\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_viewer\u001b[39m.\u001b[39;49mrender(\n\u001b[1;32m    633\u001b[0m     return_rgb_array\u001b[39m=\u001b[39;49mreturn_rgb_array, other_drawables\u001b[39m=\u001b[39;49mother_drawables\n\u001b[1;32m    634\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/hml_gridverse/lib/python3.11/site-packages/gym_gridverse/rendering.py:457\u001b[0m, in \u001b[0;36m_CustomViewer.render\u001b[0;34m(self, return_rgb_array, other_drawables)\u001b[0m\n\u001b[1;32m    455\u001b[0m     geom\u001b[39m.\u001b[39mrender()\n\u001b[1;32m    456\u001b[0m \u001b[39mfor\u001b[39;00m geom \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39monetime_geoms:\n\u001b[0;32m--> 457\u001b[0m     geom\u001b[39m.\u001b[39;49mrender()\n\u001b[1;32m    458\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform\u001b[39m.\u001b[39mdisable()\n\u001b[1;32m    460\u001b[0m \u001b[39mfor\u001b[39;00m drawable \u001b[39min\u001b[39;00m other_drawables:\n",
      "File \u001b[0;32m~/miniconda3/envs/hml_gridverse/lib/python3.11/site-packages/gym_gridverse/rendering_gym.py:189\u001b[0m, in \u001b[0;36mGeom.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    188\u001b[0m     \u001b[39mfor\u001b[39;00m attr \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattrs):\n\u001b[0;32m--> 189\u001b[0m         attr\u001b[39m.\u001b[39;49menable()\n\u001b[1;32m    190\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender1()\n\u001b[1;32m    191\u001b[0m     \u001b[39mfor\u001b[39;00m attr \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattrs:\n",
      "File \u001b[0;32m~/miniconda3/envs/hml_gridverse/lib/python3.11/site-packages/gym_gridverse/rendering_gym.py:224\u001b[0m, in \u001b[0;36mTransform.enable\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    220\u001b[0m glTranslatef(\n\u001b[1;32m    221\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranslation[\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranslation[\u001b[39m1\u001b[39m], \u001b[39m0\u001b[39m\n\u001b[1;32m    222\u001b[0m )  \u001b[39m# translate to GL loc ppint\u001b[39;00m\n\u001b[1;32m    223\u001b[0m glRotatef(RAD2DEG \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrotation, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1.0\u001b[39m)\n\u001b[0;32m--> 224\u001b[0m glScalef(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale[\u001b[39m0\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale[\u001b[39m1\u001b[39;49m], \u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/hml_gridverse/lib/python3.11/site-packages/pyglet/gl/lib.py:87\u001b[0m, in \u001b[0;36merrcheck\u001b[0;34m(result, func, arguments)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mGLException\u001b[39;00m(\u001b[39mException\u001b[39;00m):\n\u001b[1;32m     84\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merrcheck\u001b[39m(result, func, arguments):\n\u001b[1;32m     88\u001b[0m     \u001b[39mif\u001b[39;00m _debug_gl_trace:\n\u001b[1;32m     89\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Visualize agent\n",
    "env= gym.make(\"GV-FourRooms-9x9-v0\")\n",
    "env = FlattenObservationWrapper(env)\n",
    "obs = env.reset()\n",
    "lstm_states = None\n",
    "num_envs = 1\n",
    "# Episode start signals are used to reset the lstm states\n",
    "episode_starts = np.ones((num_envs,), dtype=bool)\n",
    "while True:\n",
    "    action, lstm_states = model.predict(obs, state=lstm_states, episode_start=episode_starts, deterministic=True)\n",
    "\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    episode_starts = dones\n",
    "    env.render()\n",
    "    if dones:\n",
    "        obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecurrentActorCriticPolicy(\n",
       "  (features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (pi_features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (vf_features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=64, out_features=6, bias=True)\n",
       "  (value_net): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (lstm_actor): LSTM(123, 256)\n",
       "  (lstm_critic): LSTM(123, 256)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hml_gridverse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
